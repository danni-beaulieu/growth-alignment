{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:55.914904Z",
     "start_time": "2025-12-10T21:03:55.907865Z"
    }
   },
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:55.929599Z",
     "start_time": "2025-12-10T21:03:55.927425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(img):\n",
    "    img = cv.GaussianBlur(img, (3, 3), 0)\n",
    "    img = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img)\n",
    "    return img"
   ],
   "id": "70b6c85b0cea29f7",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:55.952215Z",
     "start_time": "2025-12-10T21:03:55.950041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def keypoints(I1, I2):\n",
    "    sift = cv.SIFT_create()  # or cv.AKAZE_create() / cv.ORB_create() for speed\n",
    "    kp1, des1 = sift.detectAndCompute(I1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(I2, None)\n",
    "    return (kp1, des1), (kp2, des2)"
   ],
   "id": "95d14cd74891733a",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:55.972228Z",
     "start_time": "2025-12-10T21:03:55.969868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def match(des1, des2):\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:  # Lowe's ratio test\n",
    "            good.append(m)\n",
    "\n",
    "    # print(f\"Found {len(good)} good matches out of {len(matches)} total\")\n",
    "    return good"
   ],
   "id": "acb313a35298e8d5",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:55.990838Z",
     "start_time": "2025-12-10T21:03:55.988548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ransac(kp1, kp2, good):\n",
    "        pts1 = np.float32([kp1[m.queryIdx].pt for m in good])\n",
    "        pts2 = np.float32([kp2[m.trainIdx].pt for m in good])\n",
    "\n",
    "        M, inliers = cv.estimateAffinePartial2D(\n",
    "            pts2, pts1,\n",
    "            method=cv.RANSAC,\n",
    "            ransacReprojThreshold=3.0,\n",
    "            maxIters=2000,\n",
    "            confidence=0.99\n",
    "        )\n",
    "\n",
    "        # print(\"Affine matrix:\\n\", M)\n",
    "        return M, inliers"
   ],
   "id": "9a53e6b375b6665d",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:56.028619Z",
     "start_time": "2025-12-10T21:03:56.025132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def register(img1_full, img2_full):\n",
    "\n",
    "    img1_gray = cv.cvtColor(img1_full, cv.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv.cvtColor(img2_full, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    I1, I2 = preprocess(img1_gray), preprocess(img2_gray)\n",
    "\n",
    "    # --- 1. Detect and describe keypoints ---\n",
    "    (kp1, des1), (kp2, des2) = keypoints(I1, I2)\n",
    "\n",
    "    # --- 2. Match descriptors with ratio test ---\n",
    "    if kp1 is not None and kp2 is not None and des1 is not None and des2 is not None:\n",
    "        good = match(des1, des2)\n",
    "\n",
    "        # --- 3. Estimate affine transform using RANSAC ---\n",
    "        if len(good) >= 3:  # need at least 3 points for affine\n",
    "            M, inliers = ransac(kp1, kp2, good)\n",
    "\n",
    "            # If you need to enforce only translation, you can extract the translation components\n",
    "            # from the estimated matrix and create a new purely translational matrix.\n",
    "            # The translation components are in the last column of the affine matrix.\n",
    "            tx = M[0, 2]\n",
    "            ty = M[1, 2]\n",
    "\n",
    "            translation_matrix = np.array([[1, 0, tx],\n",
    "                                           [0, 1, ty]], dtype=np.float32)\n",
    "\n",
    "            print(\"\\nPurely Translational Matrix:\")\n",
    "            print(translation_matrix)\n",
    "\n",
    "            rows, cols, _ = img2_full.shape\n",
    "            int_tx = int(round(tx))\n",
    "            int_ty = int(round(ty))\n",
    "            return (int_tx, int_ty)\n",
    "\n",
    "        else:\n",
    "            print(\"Not enough good matches for reliable registration.\")\n",
    "    else:\n",
    "        print(\"Not enough descriptors for reliable registration.\")"
   ],
   "id": "52c00aca88c0cda5",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:56.045775Z",
     "start_time": "2025-12-10T21:03:56.043395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pipeline(fname1, fname2, dimensions):\n",
    "\n",
    "    fname1_path = \"slu_data/\" + fname1\n",
    "    fname2_path = \"slu_data/\" + fname2\n",
    "    img1 = cv.imread(fname1_path)    # reference (earlier)\n",
    "    img2 = cv.imread(fname2_path)    # moving (later)\n",
    "    dimensions[fname1] = img1.shape\n",
    "    dimensions[fname2] = img2.shape\n",
    "    result = register(img1, img2)\n",
    "\n",
    "    if result is not None:\n",
    "        return result\n",
    "    else:\n",
    "        return False"
   ],
   "id": "f13d265146e715c1",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:56.064017Z",
     "start_time": "2025-12-10T21:03:56.061345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def group_and_order_filenames(filenames, maxTP, maxLevel):\n",
    "    grouped_files = defaultdict(lambda: defaultdict(lambda: [None] * maxLevel))\n",
    "    pattern = r'^(?P<plant>[^_]+)_(?P<tube>\\d+)_(?P<level>\\d+)_(?P<date>\\d{4}-\\d{2}-\\d{2})_TP(?P<timepoint>\\d+)\\.png$'\n",
    "    #plant_tube_depth_yyyy-mm-dd_TP#\n",
    "\n",
    "    for fname in filenames:\n",
    "\n",
    "        match = re.match(pattern, fname)\n",
    "        if match:\n",
    "            plant = match.group('plant')\n",
    "            tube = int(match.group('tube'))\n",
    "            level = int(match.group('level'))\n",
    "            date = match.group('date')\n",
    "            timepoint = int(match.group('timepoint'))\n",
    "            if 1 <= level <= maxLevel:\n",
    "                grouped_files[tube][timepoint - 1][level - 1] = fname\n",
    "\n",
    "    return grouped_files"
   ],
   "id": "668c9ec42f2fb7d8",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:56.081772Z",
     "start_time": "2025-12-10T21:03:56.079203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accumulate(filename, translation, translations, references, all):\n",
    "    if filename not in references:\n",
    "        return translation\n",
    "\n",
    "    ref = references[filename]\n",
    "    if ref not in translations or ref not in all:\n",
    "        ref_translation = (0,0)\n",
    "        return tuple(map(sum, zip(translation, ref_translation)))\n",
    "    else:\n",
    "        ref_translation = translations[ref]\n",
    "        all.remove(ref)\n",
    "        return tuple(map(sum, zip(translation, accumulate(ref, ref_translation, translations, references, all))))"
   ],
   "id": "65b31efda57dc056",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:56.100092Z",
     "start_time": "2025-12-10T21:03:56.097827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imgfilelist = [f for f in os.listdir(\"slu_data\") if f.endswith(\".png\")]\n",
    "print(f\"Found {len(imgfilelist)} image files\")\n",
    "\n",
    "imgfilegroups = group_and_order_filenames(imgfilelist, 12, 7)\n",
    "print(f\"Found {len(imgfilegroups)} image groups\")"
   ],
   "id": "747589a107969d22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 image files\n",
      "Found 21 image groups\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:03:58.946191Z",
     "start_time": "2025-12-10T21:03:56.121647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for tube, timepoints in imgfilegroups.items():\n",
    "    for tp, d_files in timepoints.items():\n",
    "\n",
    "        non_none_files = list(filter(None, d_files))\n",
    "        my_iterator = iter(non_none_files)\n",
    "        translations = {}\n",
    "        references = {}\n",
    "        dimensions = {}\n",
    "        try:\n",
    "\n",
    "            current_item = next(my_iterator)\n",
    "            next_item = next(my_iterator)\n",
    "            translations[current_item] = (0,0)\n",
    "            while current_item and next_item:\n",
    "\n",
    "                translation = pipeline(current_item, next_item, dimensions)\n",
    "                if translation:\n",
    "                    translations[next_item] = translation\n",
    "                    references[next_item] = current_item\n",
    "\n",
    "                inner_iterator = iter(non_none_files)\n",
    "                try:\n",
    "                    new_item = next(inner_iterator)\n",
    "                    while not translation and new_item:\n",
    "                        if new_item == next_item or new_item == current_item:\n",
    "                            new_item = next(inner_iterator)\n",
    "                            continue\n",
    "\n",
    "                        translation = pipeline(new_item, next_item, dimensions)\n",
    "                        if translation:\n",
    "                            translations[next_item] = translation\n",
    "                            references[next_item] = new_item\n",
    "                        new_item = next(inner_iterator)\n",
    "\n",
    "                except StopIteration:\n",
    "                    current_item = next_item\n",
    "                    next_item = next(my_iterator)\n",
    "                    continue\n",
    "\n",
    "                current_item = next_item\n",
    "                next_item = next(my_iterator)\n",
    "\n",
    "        except StopIteration:\n",
    "\n",
    "            global_translations = {}\n",
    "            for f_accumulate, t_accumulate in translations.items():\n",
    "                try:\n",
    "                    all_compared = non_none_files.copy()\n",
    "                    global_t = accumulate(f_accumulate, t_accumulate, translations, references, all_compared)\n",
    "                    global_translations[f_accumulate] = global_t\n",
    "                except RecursionError:\n",
    "                    print(\"f_accumulate: \" + f_accumulate)\n",
    "\n",
    "            global_x = []\n",
    "            global_y = []\n",
    "            for key, value in global_translations.items():\n",
    "                global_x.extend([value[0], value[0] + dimensions[key][1]])\n",
    "                global_y.extend([value[1], value[1] + dimensions[key][0]])\n",
    "\n",
    "            min_x = min(global_x)\n",
    "            min_y = min(global_y)\n",
    "            max_x = max(global_x)\n",
    "            max_y = max(global_y)\n",
    "            final_cols  = max_x - min_x\n",
    "            final_rows = max_y - min_y\n",
    "            offset_x = -min_x\n",
    "            offset_y = -min_y\n",
    "\n",
    "            stitched_img = np.zeros((final_rows, final_cols, 3), dtype=img.dtype)\n",
    "            for f, t in global_translations.items():\n",
    "                f_no_ext, f_ext = os.path.splitext(f)\n",
    "                p = \"slu_data/\" + f\n",
    "                img = cv.imread(p)\n",
    "\n",
    "                c_start = t[0] + offset_x\n",
    "                r_start = t[1] + offset_y\n",
    "                # new_img = np.zeros((final_rows, final_cols, 3), dtype=img.dtype)\n",
    "\n",
    "                try:\n",
    "                    # new_img[r_start:r_start + img.shape[0], c_start:c_start + img.shape[1]] = img\n",
    "                    stitched_img[r_start:r_start + img.shape[0], c_start:c_start + img.shape[1]] = img\n",
    "                except ValueError:\n",
    "                    print(\"f: \" + f)\n",
    "\n",
    "                # cv.imwrite(\"slu_data/\" + f_no_ext + \"_sift_depths.png\", new_img)\n",
    "            cv.imwrite(\"slu_data/kura_\" + str(tube) + \"_TP\" + str(tp + 1) + \"_sift_depths.png\", stitched_img)\n",
    "\n",
    "            continue"
   ],
   "id": "3a59303e630f0c50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.          0.        773.06494  ]\n",
      " [  0.          1.          6.6860194]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.         0.       799.33765 ]\n",
      " [  0.         1.         4.508773]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.          0.        801.3615   ]\n",
      " [  0.          1.          5.7434916]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.         0.       800.76825 ]\n",
      " [  0.         1.         5.448008]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.         0.       801.3292  ]\n",
      " [  0.         1.         6.064692]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.          0.        806.36676  ]\n",
      " [  0.          1.          4.5280976]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.          0.        809.51025  ]\n",
      " [  0.          1.          1.4867431]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.          0.        795.17194  ]\n",
      " [  0.          1.          3.2237055]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.          0.        798.9673   ]\n",
      " [  0.          1.          3.3665955]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.         0.       800.7327  ]\n",
      " [  0.         1.         4.163474]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[ 1.0000000e+00  0.0000000e+00  8.0776434e+02]\n",
      " [ 0.0000000e+00  1.0000000e+00 -3.6768177e-01]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.          0.        803.5721   ]\n",
      " [  0.          1.          2.0576134]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.          0.        795.47614  ]\n",
      " [  0.          1.         -3.2592468]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.         0.       802.5335  ]\n",
      " [  0.         1.        -8.149348]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[  1.          0.        801.34296  ]\n",
      " [  0.          1.          5.2344623]]\n"
     ]
    }
   ],
   "execution_count": 171
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
