{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.511241Z",
     "start_time": "2025-12-10T21:21:46.503242Z"
    }
   },
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.537366Z",
     "start_time": "2025-12-10T21:21:46.533934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(img):\n",
    "    img = cv.GaussianBlur(img, (3, 3), 0)\n",
    "    img = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img)\n",
    "    return img"
   ],
   "id": "70b6c85b0cea29f7",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.578910Z",
     "start_time": "2025-12-10T21:21:46.575642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def keypoints(I1, I2):\n",
    "    sift = cv.SIFT_create()  # or cv.AKAZE_create() / cv.ORB_create() for speed\n",
    "    kp1, des1 = sift.detectAndCompute(I1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(I2, None)\n",
    "    return (kp1, des1), (kp2, des2)"
   ],
   "id": "95d14cd74891733a",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.613768Z",
     "start_time": "2025-12-10T21:21:46.610222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def match(des1, des2):\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:  # Lowe's ratio test\n",
    "            good.append(m)\n",
    "\n",
    "    # print(f\"Found {len(good)} good matches out of {len(matches)} total\")\n",
    "    return good"
   ],
   "id": "acb313a35298e8d5",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.648059Z",
     "start_time": "2025-12-10T21:21:46.643628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ransac(kp1, kp2, good):\n",
    "        pts1 = np.float32([kp1[m.queryIdx].pt for m in good])\n",
    "        pts2 = np.float32([kp2[m.trainIdx].pt for m in good])\n",
    "\n",
    "        M, inliers = cv.estimateAffinePartial2D(\n",
    "            pts2, pts1,\n",
    "            method=cv.RANSAC,\n",
    "            ransacReprojThreshold=3.0,\n",
    "            maxIters=2000,\n",
    "            confidence=0.99\n",
    "        )\n",
    "\n",
    "        # print(\"Affine matrix:\\n\", M)\n",
    "        return M, inliers"
   ],
   "id": "9a53e6b375b6665d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.719989Z",
     "start_time": "2025-12-10T21:21:46.712348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def register(img1_full, img2_full):\n",
    "\n",
    "    img1_gray = cv.cvtColor(img1_full, cv.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv.cvtColor(img2_full, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    I1, I2 = preprocess(img1_gray), preprocess(img2_gray)\n",
    "\n",
    "    # --- 1. Detect and describe keypoints ---\n",
    "    (kp1, des1), (kp2, des2) = keypoints(I1, I2)\n",
    "\n",
    "    # --- 2. Match descriptors with ratio test ---\n",
    "    if kp1 is not None and kp2 is not None and des1 is not None and des2 is not None:\n",
    "        good = match(des1, des2)\n",
    "\n",
    "        # --- 3. Estimate affine transform using RANSAC ---\n",
    "        if len(good) >= 3:  # need at least 3 points for affine\n",
    "            M, inliers = ransac(kp1, kp2, good)\n",
    "\n",
    "            # If you need to enforce only translation, you can extract the translation components\n",
    "            # from the estimated matrix and create a new purely translational matrix.\n",
    "            # The translation components are in the last column of the affine matrix.\n",
    "            tx = M[0, 2]\n",
    "            ty = M[1, 2]\n",
    "\n",
    "            translation_matrix = np.array([[1, 0, tx],\n",
    "                                           [0, 1, ty]], dtype=np.float32)\n",
    "\n",
    "            print(\"\\nPurely Translational Matrix:\")\n",
    "            print(translation_matrix)\n",
    "\n",
    "            rows, cols, _ = img2_full.shape\n",
    "            int_tx = int(round(tx))\n",
    "            int_ty = int(round(ty))\n",
    "            return (int_tx, int_ty)\n",
    "\n",
    "        else:\n",
    "            print(\"Not enough good matches for reliable registration.\")\n",
    "    else:\n",
    "        print(\"Not enough descriptors for reliable registration.\")"
   ],
   "id": "52c00aca88c0cda5",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.748634Z",
     "start_time": "2025-12-10T21:21:46.744805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pipeline(fname1, fname2, dimensions):\n",
    "\n",
    "    fname1_path = \"slu_data/\" + fname1\n",
    "    fname2_path = \"slu_data/\" + fname2\n",
    "    img1 = cv.imread(fname1_path)    # reference (earlier)\n",
    "    img2 = cv.imread(fname2_path)    # moving (later)\n",
    "    dimensions[fname1] = img1.shape\n",
    "    dimensions[fname2] = img2.shape\n",
    "    result = register(img1, img2)\n",
    "\n",
    "    if result is not None:\n",
    "        return result\n",
    "    else:\n",
    "        return False"
   ],
   "id": "f13d265146e715c1",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.780333Z",
     "start_time": "2025-12-10T21:21:46.775918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def group_and_order_filenames(filenames, maxTP):\n",
    "    grouped_files = defaultdict(lambda: [None] * maxTP)\n",
    "    pattern = r'^(?P<plant>[^_]+)_(?P<tube>\\d+)_TP(?P<timepoint>\\d+)\\_sift_depths.png$'\n",
    "    #plant_tube_depth_yyyy-mm-dd_TP#\n",
    "\n",
    "    for fname in filenames:\n",
    "\n",
    "        match = re.match(pattern, fname)\n",
    "        if match:\n",
    "            plant = match.group('plant')\n",
    "            tube = int(match.group('tube'))\n",
    "            timepoint = int(match.group('timepoint'))\n",
    "            if 1 <= timepoint <= maxTP:\n",
    "                grouped_files[tube][timepoint - 1] = fname\n",
    "\n",
    "    return grouped_files"
   ],
   "id": "668c9ec42f2fb7d8",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.815370Z",
     "start_time": "2025-12-10T21:21:46.810288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accumulate(filename, translation, translations, references, all):\n",
    "    if filename not in references:\n",
    "        return translation\n",
    "\n",
    "    ref = references[filename]\n",
    "    if ref not in translations or ref not in all:\n",
    "        ref_translation = (0,0)\n",
    "        return tuple(map(sum, zip(translation, ref_translation)))\n",
    "    else:\n",
    "        ref_translation = translations[ref]\n",
    "        all.remove(ref)\n",
    "        return tuple(map(sum, zip(translation, accumulate(ref, ref_translation, translations, references, all))))"
   ],
   "id": "65b31efda57dc056",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:46.846917Z",
     "start_time": "2025-12-10T21:21:46.843438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imgfilelist = [f for f in os.listdir(\"slu_data\") if f.endswith(\".png\")]\n",
    "print(f\"Found {len(imgfilelist)} image files\")\n",
    "\n",
    "imgfilegroups = group_and_order_filenames(imgfilelist, 12)\n",
    "print(f\"Found {len(imgfilegroups)} image groups\")"
   ],
   "id": "747589a107969d22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 image files\n",
      "Found 1 image groups\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:21:50.548041Z",
     "start_time": "2025-12-10T21:21:46.877851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for tube, tp_files in imgfilegroups.items():\n",
    "\n",
    "        non_none_files = list(filter(None, tp_files))\n",
    "        my_iterator = iter(non_none_files)\n",
    "        translations = {}\n",
    "        references = {}\n",
    "        dimensions = {}\n",
    "        try:\n",
    "\n",
    "            current_item = next(my_iterator)\n",
    "            next_item = next(my_iterator)\n",
    "            translations[current_item] = (0,0)\n",
    "            while current_item and next_item:\n",
    "\n",
    "                translation = pipeline(current_item, next_item, dimensions)\n",
    "                if translation:\n",
    "                    translations[next_item] = translation\n",
    "                    references[next_item] = current_item\n",
    "\n",
    "                inner_iterator = iter(non_none_files)\n",
    "                try:\n",
    "                    new_item = next(inner_iterator)\n",
    "                    while not translation and new_item:\n",
    "                        if new_item == next_item or new_item == current_item:\n",
    "                            new_item = next(inner_iterator)\n",
    "                            continue\n",
    "\n",
    "                        translation = pipeline(new_item, next_item, dimensions)\n",
    "                        if translation:\n",
    "                            translations[next_item] = translation\n",
    "                            references[next_item] = new_item\n",
    "                        new_item = next(inner_iterator)\n",
    "\n",
    "                except StopIteration:\n",
    "                    current_item = next_item\n",
    "                    next_item = next(my_iterator)\n",
    "                    continue\n",
    "\n",
    "                current_item = next_item\n",
    "                next_item = next(my_iterator)\n",
    "\n",
    "        except StopIteration:\n",
    "\n",
    "            global_translations = {}\n",
    "            for f_accumulate, t_accumulate in translations.items():\n",
    "                try:\n",
    "                    all_compared = non_none_files.copy()\n",
    "                    global_t = accumulate(f_accumulate, t_accumulate, translations, references, all_compared)\n",
    "                    global_translations[f_accumulate] = global_t\n",
    "                except RecursionError:\n",
    "                    print(\"f_accumulate: \" + f_accumulate)\n",
    "\n",
    "            global_x = []\n",
    "            global_y = []\n",
    "            for key, value in global_translations.items():\n",
    "                global_x.extend([value[0], value[0] + dimensions[key][1]])\n",
    "                global_y.extend([value[1], value[1] + dimensions[key][0]])\n",
    "\n",
    "            min_x = min(global_x)\n",
    "            min_y = min(global_y)\n",
    "            max_x = max(global_x)\n",
    "            max_y = max(global_y)\n",
    "            final_cols  = max_x - min_x\n",
    "            final_rows = max_y - min_y\n",
    "            offset_x = -min_x\n",
    "            offset_y = -min_y\n",
    "\n",
    "            for f, t in global_translations.items():\n",
    "                f_no_ext, f_ext = os.path.splitext(f)\n",
    "                p = \"slu_data/\" + f\n",
    "                img = cv.imread(p)\n",
    "\n",
    "                c_start = t[0] + offset_x\n",
    "                r_start = t[1] + offset_y\n",
    "                new_img = np.zeros((final_rows, final_cols, 3), dtype=img.dtype)\n",
    "\n",
    "                try:\n",
    "                    new_img[r_start:r_start + img.shape[0], c_start:c_start + img.shape[1]] = img\n",
    "                except ValueError:\n",
    "                    print(\"f: \" + f)\n",
    "\n",
    "                cv.imwrite(\"slu_data/\" + f_no_ext + \"_all.png\", new_img)\n",
    "\n",
    "            continue"
   ],
   "id": "3a59303e630f0c50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Purely Translational Matrix:\n",
      "[[   1.          0.        -31.178421]\n",
      " [   0.          1.       -100.42439 ]]\n",
      "\n",
      "Purely Translational Matrix:\n",
      "[[ 1.        0.       10.427353]\n",
      " [ 0.        1.       33.741127]]\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
