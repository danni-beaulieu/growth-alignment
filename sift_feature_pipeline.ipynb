{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T02:56:02.781790Z",
     "start_time": "2025-11-21T02:56:02.773096Z"
    }
   },
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:56:02.788696Z",
     "start_time": "2025-11-21T02:56:02.785744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(img):\n",
    "    img = cv.GaussianBlur(img, (3, 3), 0)\n",
    "    img = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img)\n",
    "    return img"
   ],
   "id": "70b6c85b0cea29f7",
   "outputs": [],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:56:02.809828Z",
     "start_time": "2025-11-21T02:56:02.807698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def keypoints(I1, I2):\n",
    "    sift = cv.SIFT_create()  # or cv.AKAZE_create() / cv.ORB_create() for speed\n",
    "    kp1, des1 = sift.detectAndCompute(I1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(I2, None)\n",
    "    return (kp1, des1), (kp2, des2)"
   ],
   "id": "95d14cd74891733a",
   "outputs": [],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:56:02.821954Z",
     "start_time": "2025-11-21T02:56:02.820024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def match(des1, des2):\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:  # Lowe's ratio test\n",
    "            good.append(m)\n",
    "\n",
    "    # print(f\"Found {len(good)} good matches out of {len(matches)} total\")\n",
    "    return good"
   ],
   "id": "acb313a35298e8d5",
   "outputs": [],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:56:02.831706Z",
     "start_time": "2025-11-21T02:56:02.829769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ransac(kp1, kp2, good):\n",
    "        pts1 = np.float32([kp1[m.queryIdx].pt for m in good])\n",
    "        pts2 = np.float32([kp2[m.trainIdx].pt for m in good])\n",
    "\n",
    "        M, inliers = cv.estimateAffinePartial2D(\n",
    "            pts2, pts1,\n",
    "            method=cv.RANSAC,\n",
    "            ransacReprojThreshold=3.0,\n",
    "            maxIters=2000,\n",
    "            confidence=0.99\n",
    "        )\n",
    "\n",
    "        # print(\"Affine matrix:\\n\", M)\n",
    "        return M, inliers"
   ],
   "id": "9a53e6b375b6665d",
   "outputs": [],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:56:02.841545Z",
     "start_time": "2025-11-21T02:56:02.839232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def display(img1_full, img1_gray, img2_full, img2_gray, show=False):\n",
    "\n",
    "    blue_tinted_image = np.zeros_like(img1_full)\n",
    "    blue_tinted_image[:, :, 0] = img1_gray\n",
    "    red_tinted_image = np.zeros_like(img2_full)\n",
    "    red_tinted_image[:, :, 2] = img2_gray\n",
    "\n",
    "    overlay = cv.addWeighted(blue_tinted_image, 0.5, red_tinted_image, 0.5, 0)\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(24,12))\n",
    "        plt.subplot(1,1,1); plt.imshow(overlay); plt.title(\"Overlay after alignment\")\n",
    "        plt.show()\n",
    "\n",
    "    return overlay"
   ],
   "id": "b268bb3c172c4498",
   "outputs": [],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:56:02.852479Z",
     "start_time": "2025-11-21T02:56:02.849296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def register(img1_full, img2_full):\n",
    "\n",
    "    img1_gray = cv.cvtColor(img1_full, cv.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv.cvtColor(img2_full, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    I1, I2 = preprocess(img1_gray), preprocess(img2_gray)\n",
    "\n",
    "    # --- 1. Detect and describe keypoints ---\n",
    "    (kp1, des1), (kp2, des2) = keypoints(I1, I2)\n",
    "\n",
    "    # --- 2. Match descriptors with ratio test ---\n",
    "    if kp1 is not None and kp2 is not None and des1 is not None and des2 is not None:\n",
    "        good = match(des1, des2)\n",
    "\n",
    "        # --- 3. Estimate affine transform using RANSAC ---\n",
    "        if len(good) >= 3:  # need at least 3 points for affine\n",
    "            M, inliers = ransac(kp1, kp2, good)\n",
    "\n",
    "            # If you need to enforce only translation, you can extract the translation components\n",
    "            # from the estimated matrix and create a new purely translational matrix.\n",
    "            # The translation components are in the last column of the affine matrix.\n",
    "            # tx = M[0, 2]\n",
    "            # ty = M[1, 2]\n",
    "\n",
    "            # Create a purely translational matrix\n",
    "            # translation_matrix = np.array([[1, 0, tx],\n",
    "            #                                [0, 1, ty]], dtype=np.float32)\n",
    "\n",
    "            # print(\"\\nPurely Translational Matrix:\")\n",
    "            # print(translation_matrix)\n",
    "\n",
    "            # --- 4. Warp moving image ---\n",
    "            aligned_gray = cv.warpAffine(\n",
    "                img2_gray, M, (img2_gray.shape[1], img2_gray.shape[0]),\n",
    "                flags=cv.INTER_LINEAR\n",
    "            )\n",
    "            aligned_full = cv.warpAffine(\n",
    "                img2_full, M, (img2_full.shape[1], img2_full.shape[0]),\n",
    "                flags=cv.INTER_LINEAR\n",
    "            )\n",
    "            # aligned_gray = cv.warpAffine(img2_gray, translation_matrix, (img2_gray.shape[1], img2_gray.shape[0]))\n",
    "            # aligned_full = cv.warpAffine(img2_full, translation_matrix, (img2_full.shape[1], img2_full.shape[0]))\n",
    "\n",
    "            # --- 5. Quick visual check ---\n",
    "            overlay = display(img1_full, img1_gray, aligned_full, aligned_gray)\n",
    "            return aligned_full, overlay\n",
    "\n",
    "        else:\n",
    "            print(\"Not enough good matches for reliable registration.\")\n",
    "    else:\n",
    "        print(\"Not enough descriptors for reliable registration.\")"
   ],
   "id": "52c00aca88c0cda5",
   "outputs": [],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:56:02.861151Z",
     "start_time": "2025-11-21T02:56:02.859263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pipeline(fname1, fname2):\n",
    "    img1 = cv.imread(fname1)    # reference (earlier)\n",
    "    img2 = cv.imread(fname2)      # moving (later)\n",
    "\n",
    "    result = register(img1, img2)\n",
    "\n",
    "    if result is not None:\n",
    "        aligned_full, overlay = result\n",
    "        filename_without_extension, file_extension = os.path.splitext(fname2)\n",
    "        cv.imwrite(filename_without_extension + \"_sift.png\", aligned_full)\n",
    "        cv.imwrite(filename_without_extension + \"_sift_overlay.png\", overlay)"
   ],
   "id": "f13d265146e715c1",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:56:02.871215Z",
     "start_time": "2025-11-21T02:56:02.868978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def group_and_order_filenames(filenames, maxTP, maxLevel):\n",
    "    grouped_files = defaultdict(lambda: defaultdict(lambda: [None] * maxTP))\n",
    "    pattern = r'^(?P<plant>[^_]+)_(?P<tube>\\d+)_(?P<level>\\d+)_(?P<date>\\d{4}-\\d{2}-\\d{2})_TP(?P<timepoint>\\d+)\\.png$'\n",
    "    #plant_tube_depth_yyyy-mm-dd_TP#\n",
    "\n",
    "    for fname in filenames:\n",
    "\n",
    "        match = re.match(pattern, fname)\n",
    "        if match:\n",
    "            plant = match.group('plant')\n",
    "            tube = int(match.group('tube'))\n",
    "            level = int(match.group('level'))\n",
    "            date = match.group('date')\n",
    "            timepoint = int(match.group('timepoint'))\n",
    "            if 1 <= timepoint <= maxTP:\n",
    "                grouped_files[tube][level - 1][timepoint - 1] = fname\n",
    "\n",
    "    return grouped_files"
   ],
   "id": "668c9ec42f2fb7d8",
   "outputs": [],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:13:58.485262Z",
     "start_time": "2025-11-21T17:13:58.443435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imgfilelist = [f for f in os.listdir(\"slu_data\") if f.endswith(\".png\")]\n",
    "print(f\"Found {len(imgfilelist)} image files\")\n",
    "\n",
    "imgfilegroups = group_and_order_filenames(imgfilelist, 12, 7)\n",
    "print(f\"Found {len(imgfilelist)} image groups\")"
   ],
   "id": "747589a107969d22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 83 image files\n",
      "Found 83 image groups\n"
     ]
    }
   ],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:14:12.955250Z",
     "start_time": "2025-11-21T17:13:59.878157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for tube, depths in imgfilegroups.items():\n",
    "    for depth, tp_files in depths.items():\n",
    "        # for i in range(0, len(tp_files) - 1):\n",
    "        #     pipeline(\"slu_data/\" + tp_files[i], \"slu_data/\" + tp_files[i + 1])\n",
    "        non_none_files = filter(None, tp_files)\n",
    "        my_iterator = iter(non_none_files)\n",
    "        try:\n",
    "            next_item = next(my_iterator)\n",
    "            while next_item:\n",
    "                current_item = next_item\n",
    "                next_item = next(my_iterator)\n",
    "                if current_item and next_item:\n",
    "                    current_without_extension, current_extension = os.path.splitext(current_item)\n",
    "                    if os.path.exists(\"slu_data/\" + current_without_extension + \"_sift.png\"):\n",
    "                        pipeline(\"slu_data/\" + current_without_extension + \"_sift.png\", \"slu_data/\" + next_item)\n",
    "                    else:\n",
    "                        pipeline(\"slu_data/\" + current_item, \"slu_data/\" + next_item)\n",
    "        except StopIteration:\n",
    "            continue"
   ],
   "id": "3a59303e630f0c50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough good matches for reliable registration.\n"
     ]
    }
   ],
   "execution_count": 220
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
